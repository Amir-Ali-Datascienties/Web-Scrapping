{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. Web scraping software may directly access the World Wide Web using the Hypertext Transfer Protocol or a web browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python package for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bs4\n",
    "#!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_page = requests.get('https://en.wikipedia.org')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_soup = BeautifulSoup(wiki_page.content)\n",
    "#wiki_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Page\n",
      "From today's featured article\n",
      "\n",
      "Personal tools\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Scraping Header tags\n",
    "\n",
    "header_wiki = wiki_soup.find('h1')\n",
    "header_wiki.text\n",
    "\n",
    "head_list = ['h1', 'h2', 'h3']\n",
    "l_head = len(head_list)\n",
    "\n",
    "for i in range (l_head):\n",
    "    header_wiki = wiki_soup.find(head_list[i]).text\n",
    "    print(header_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From today's featured article\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_wiki = wiki_soup.find('h2')\n",
    "header_wiki.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPersonal tools\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_wiki = wiki_soup.find('h3')\n",
    "header_wiki.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)\n",
    "and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_page = requests.get('https://www.imdb.com/chart/top/')\n",
    "imdb_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_soup = BeautifulSoup(imdb_page.content)\n",
    "#imbd_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "movies = imdb_soup.find('tbody', class_ = 'lister-list').find_all('tr')\n",
    "#tbody is tag where al ther related tag available\n",
    "#in the tbody tag we have tr tage which is use for each different movie attributes.\n",
    "print(len(movies)) # by printing length of movive tag we can count how  many tr tags or different movies available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lest write for loop to itreate each 'tr' tag\n",
    "\n",
    "for movie in movies:\n",
    "    movie_name = movie.find('td', class_ = 'titleColumn').a.text# in every 'tr' tag their is 'td' tags where movie name present'\n",
    "    #in class 'titleColumn' movie title/movie name present.\n",
    "    rank = movie.find('td', class_ = 'titleColumn').text\n",
    "    rank = movie.find('td', class_ = 'titleColumn').get_text(strip = True)\n",
    "    rank = movie.find('td', class_ = 'titleColumn').get_text(strip = True).split('.')[0]\n",
    "    # if we use '.text' it will return all the tags text within 'td' tag\n",
    "    #strip = true is atribute used to remove all the speacial char and new lines.\n",
    "    # we can use split function to get rating only, which we done in last rank code line.\n",
    "    released_year = movie.find('td', class_ = 'titleColumn').span.text.strip('()') #strip '()' to avoid prenthesis\n",
    "    rating = movie.find('td', class_ = 'ratingColumn imdbRating').get_text(strip = True) #strip = True to avoid special char.\n",
    "#     print(movie_name)\n",
    " #   print(rank)\n",
    "#     print(rating)\n",
    "#     print(released_year)\n",
    "    \n",
    "#     print(rank,movie_name,released_year, rating)\n",
    "#     if rank == '100':\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_movies = []\n",
    "for movie in movies:\n",
    "    movie_name = movie.find('td', class_ = 'titleColumn').a.text\n",
    "    imdb_movies.append(movie_name)\n",
    "    if len(imdb_movies) == 100:\n",
    "        break\n",
    "#print(imdb_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_rank = []\n",
    "for movie in movies:\n",
    "    ranks = movie.find('td', class_ = 'titleColumn').get_text(strip = True).split('.')[0]\n",
    "    imdb_rank.append(ranks)\n",
    "    if len(imdb_rank) == 100:\n",
    "        break\n",
    "#print(imdb_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_rating = []\n",
    "for movie in movies:\n",
    "    rating = movie.find('td', class_ = 'ratingColumn imdbRating').get_text(strip = True)\n",
    "    imdb_rating.append(rating)\n",
    "    if len(imdb_rating) == 100:\n",
    "        break\n",
    "#print(imdb_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_released = []\n",
    "for movie in movies:\n",
    "    released = movie.find('td', class_ = 'titleColumn').span.text\n",
    "    movie_released.append(released)\n",
    "    if len(movie_released) == 100:\n",
    "        break\n",
    "#movie_released"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Imdb Rank</th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Released Year</th>\n",
       "      <th>Imdb Ratting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>(1974)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>(1957)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Citizen Kane</td>\n",
       "      <td>(1941)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>(1931)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Lawrence of Arabia</td>\n",
       "      <td>(1962)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>(1959)</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Vertigo</td>\n",
       "      <td>(1958)</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Imdb Rank                         Movie Name Released Year Imdb Ratting\n",
       "0          1           The Shawshank Redemption        (1994)          9.2\n",
       "1          2                      The Godfather        (1972)          9.2\n",
       "2          3                    The Dark Knight        (2008)          9.0\n",
       "3          4              The Godfather Part II        (1974)          9.0\n",
       "4          5                       12 Angry Men        (1957)          9.0\n",
       "..       ...                                ...           ...          ...\n",
       "95        96                       Citizen Kane        (1941)          8.3\n",
       "96        97  M - Eine Stadt sucht einen Mörder        (1931)          8.3\n",
       "97        98                 Lawrence of Arabia        (1962)          8.3\n",
       "98        99                 North by Northwest        (1959)          8.2\n",
       "99       100                            Vertigo        (1958)          8.2\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Imdb Rank':imdb_rank,'Movie Name':imdb_movies,'Released Year':movie_released,'Imdb Ratting':imdb_rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of\n",
    "release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_hi_page = requests.get(\"https://www.imdb.com/india/top-rated-indian-movies/\")\n",
    "imdb_hi_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_page_soup = BeautifulSoup(imdb_hi_page.content)\n",
    "#hi_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_movies = hi_page_soup.find('tbody', class_ = 'lister-list').find_all('tr')\n",
    "len(hindi_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100']\n"
     ]
    }
   ],
   "source": [
    "imdb_rank = []\n",
    "\n",
    "for movie in hindi_movies:\n",
    "    movies = movie.find('td', class_ = 'titleColumn').get_text(strip = True).split('.')[0]\n",
    "    imdb_rank.append(movies)\n",
    "    if len(imdb_rank) == 100:\n",
    "        break\n",
    "print(imdb_rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ramayana: The Legend of Prince Rama', 'Rocketry: The Nambi Effect', 'Golmaal', '777 Charlie', 'Nayakan', 'Anbe Sivam', 'Jai Bhim', 'Pariyerum Perumal', '3 Idiots', 'Apur Sansar', 'Manichitrathazhu', 'Kantara', '#Home', 'Black Friday', 'Kumbalangi Nights', 'Soorarai Pottru', 'Taare Zameen Par', 'C/o Kancharapalem', 'Kireedam', 'Dangal', 'Kaithi', 'Jersey', '96', 'Asuran', 'Thevar Magan', 'Natsamrat', 'Drishyam 2', 'Visaaranai', 'Sita Ramam', 'Thalapathi', 'Pather Panchali', 'Sarpatta Parambarai', 'Jaane Bhi Do Yaaro', 'Thani Oruvan', 'Sardar Udham', 'Aparajito', 'Drishyam', 'Khosla Ka Ghosla!', 'Vada Chennai', 'Ratsasan', 'Chupke Chupke', 'Anniyan', 'Peranbu', 'Mahanati', 'Satya', 'Gangs of Wasseypur', 'Bangalore Days', 'Premam', 'Agent Sai Srinivasa Athreya', 'Drishyam', 'Devasuram', 'Super Deluxe', 'Bhaag Milkha Bhaag', 'Tumbbad', 'Andhadhun', 'Vikram Vedha', 'Guide', 'Chithram', 'Vikram', 'Kannathil Muthamittal', 'Zindagi Na Milegi Dobara', 'Sairat', 'Shahid', 'Aruvi', 'Paan Singh Tomar', 'Iruvar', 'Chhichhore', 'Swades: We, the People', 'Pyaasa', 'Drishyam 2', 'Chak De! India', 'Spadikam', 'Munna Bhai M.B.B.S.', 'Uri: The Surgical Strike', 'Mudhalvan', 'Black', 'Jo Jeeta Wohi Sikandar', 'Dhuruvangal Pathinaaru', 'Lagaan: Once Upon a Time in India', 'Hera Pheri', 'Papanasam', 'Pudhu Pettai', 'Queen', 'PK', 'Article 15', 'Talvar', 'Sarfarosh', 'OMG: Oh My God!', 'Soodhu Kavvum', 'Mandela', 'Sholay', 'Udaan', 'Barfi!', 'Jigarthanda', 'The Legend of Bhagat Singh', 'Kaakkaa Muttai', 'Ustad Hotel', 'Theeran Adhigaaram Ondru', 'Angoor', 'Rang De Basanti']\n"
     ]
    }
   ],
   "source": [
    "imdb_movie = []\n",
    "\n",
    "for movie in hindi_movies:\n",
    "    movies = movie.find('td', class_ = \"titleColumn\").a.text\n",
    "    imdb_movie.append(movies)\n",
    "    if len(imdb_movie) == 100:\n",
    "        break\n",
    "print(imdb_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8.5', '8.4', '8.4', '8.4', '8.4', '8.4', '8.4', '8.4', '8.4', '8.4', '8.3', '8.3', '8.3', '8.3', '8.3', '8.3', '8.3', '8.3', '8.3', '8.3', '8.3', '8.3', '8.2', '8.2', '8.2', '8.2', '8.2', '8.2', '8.2', '8.2', '8.2', '8.2', '8.2', '8.2', '8.2', '8.2', '8.2', '8.2', '8.2', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.0', '8.0', '8.0', '8.0', '8.0', '8.0', '8.0', '8.0', '8.0', '8.0', '8.0', '8.0', '8.0', '8.0', '8.0', '8.0', '8.0', '8.0', '8.0', '8.0']\n"
     ]
    }
   ],
   "source": [
    "imdb_ratting = []\n",
    "\n",
    "for movie in hindi_movies:\n",
    "    movies = movie.find('td', class_ = 'ratingColumn imdbRating').get_text(strip = True)\n",
    "    imdb_ratting.append(movies)\n",
    "    if len(imdb_ratting) == 100:\n",
    "        break\n",
    "print(imdb_ratting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1993', '2022', '1979', '2022', '1987', '2003', '2021', '2018', '2009', '1959', '1993', '2022', '2021', '2004', '2019', '2020', '2007', '2018', '1989', '2016', '2019', '2019', '2018', '2019', '1992', '2016', '2021', '2015', '2022', '1991', '1955', '2021', '1983', '2015', '2021', '1956', '2013', '2006', '2018', '2018', '1975', '2005', '2018', '2018', '1998', '2012', '2014', '2015', '2019', '2015', '1993', '2019', '2013', '2018', '2018', '2017', '1965', '1988', '2022', '2002', '2011', '2016', '2012', '2016', '2012', '1997', '2019', '2004', '1957', '2022', '2007', '1995', '2003', '2019', '1999', '2005', '1992', '2016', '2001', '2000', '2015', '2006', '2013', '2014', '2019', '2015', '1999', '2012', '2013', '2021', '1975', '2010', '2012', '2014', '2002', '2014', '2012', '2017', '1982', '2006']\n"
     ]
    }
   ],
   "source": [
    "released_year = []\n",
    "\n",
    "for movie in hindi_movies:\n",
    "    movies = movie.find('td', class_ = 'titleColumn').span.text.strip(\"()\")\n",
    "    released_year.append(movies)\n",
    "    if len(released_year) == 100:\n",
    "        break\n",
    "print(released_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Imdb Rank':imdb_rank,'Movie Name':imdb_movie,'Released Year':released_year,'Imdb Ratting':imdb_ratting})\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) \n",
    "from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "president = requests.get(\"https://presidentofindia.nic.in/former-presidents.htm\")\n",
    "#print(president.text[0:])\n",
    "soup = BeautifulSoup(president.content)\n",
    "#soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_president = soup.find_all('div', class_ = \"presidentListing\")\n",
    "len(all_president)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shri Ram Nath Kovind (birth - 1945)Term of Office:25 July, 2017 to 25 July, 2022https://ramnathkovind.nic.in',\n",
       " 'Shri Pranab Mukherjee (1935-2020)Term of Office:25 July, 2012 to 25 July, 2017http://pranabmukherjee.nic.in',\n",
       " 'Smt Pratibha Devisingh Patil (birth - 1934)Term of Office:25 July, 2007 to 25 July, 2012http://pratibhapatil.nic.in',\n",
       " 'DR. A.P.J. Abdul Kalam (1931-2015)Term of Office:25 July, 2002 to 25 July, 2007http://abdulkalam.nic.in',\n",
       " 'Shri K. R. Narayanan (1920 - 2005)Term of Office:25 July, 1997 to 25 July, 2002',\n",
       " 'Dr Shankar Dayal Sharma (1918-1999)Term of Office:25 July, 1992 to 25 July, 1997',\n",
       " 'Shri R Venkataraman (1910-2009)Term of Office:25 July, 1987 to 25 July, 1992',\n",
       " 'Giani Zail Singh (1916-1994)Term of Office:25 July, 1982 to 25 July, 1987',\n",
       " 'Shri Neelam Sanjiva Reddy (1913-1996)Term of Office:25 July, 1977 to 25 July, 1982',\n",
       " 'Dr. Fakhruddin Ali Ahmed (1905-1977)Term of Office:24 August, 1974 to 11 February, 1977',\n",
       " 'Shri Varahagiri Venkata Giri (1894-1980)Term of Office:3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974',\n",
       " 'Dr. Zakir Husain (1897-1969)Term of Office:13 May, 1967 to 3 May, 1969',\n",
       " 'Dr. Sarvepalli Radhakrishnan (1888-1975)Term of Office:13 May, 1962 to 13 May, 1967',\n",
       " 'Dr. Rajendra Prasad (1884-1963)Term of Office:26 January, 1950 to 13 May, 1962']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "president_name = []\n",
    "for i in all_president:\n",
    "    president_name.append(i.get_text(strip = True))\n",
    "president_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term of office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 25 July, 2017 to 25 July, 2022 ', ' 25 July, 2012 to 25 July, 2017 ', ' 25 July, 2007 to 25 July, 2012 ', ' 25 July, 2002 to 25 July, 2007 ', ' 25 July, 1997 to 25 July, 2002 ', ' 25 July, 1992 to 25 July, 1997 ', ' 25 July, 1987 to 25 July, 1992 ', ' 25 July, 1982 to 25 July, 1987 ', ' 25 July, 1977 to 25 July, 1982 ', ' 24 August, 1974 to 11 February, 1977', ' 3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974', ' 13 May, 1967 to 3 May, 1969', ' 13 May, 1962 to 13 May, 1967', ' 26 January, 1950 to 13 May, 1962']\n"
     ]
    }
   ],
   "source": [
    "term_office = []\n",
    "for i in all_president:\n",
    "    term_office.append(i.text.split(\":\")[1].split(\"\\n\")[0])\n",
    "print(term_office)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cricket_page = requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "cricket_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cricket_soup = BeautifulSoup(cricket_page.content)\n",
    "#cricket_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']\n"
     ]
    }
   ],
   "source": [
    "all_team = cricket_soup.find('tbody').find_all('tr', class_ = 'table-body')\n",
    "rank = []\n",
    "\n",
    "for i in all_team:\n",
    "    team = i.find('td', class_ = 'table-body__cell table-body__cell--position u-text-right').text\n",
    "    rank.append(team)\n",
    "\n",
    "print(rank)\n",
    "\n",
    "# len(first_team)\n",
    "# print(first_team)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['England', 'Australia', 'India', 'Pakistan', 'South Africa', 'Bangladesh', 'Sri Lanka', 'Afghanistan', 'West Indies', 'Ireland', 'Scotland', 'Zimbabwe', 'Namibia', 'Netherlands', 'Oman', 'UAE', 'United States', 'Nepal', 'Papua New Guinea']\n"
     ]
    }
   ],
   "source": [
    "team_name = []\n",
    "\n",
    "for i in all_team:\n",
    "    team = i.find('td', class_ = \"table-body__cell rankings-table__team\").find('span', class_ = 'u-hide-phablet').text\n",
    "    team_name.append(team)\n",
    "print(team_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['30', '32', '35', '22', '24', '30', '30', '19', '41', '23', '27', '26', '23', '21', '30', '25', '31', '25', '30']\n"
     ]
    }
   ],
   "source": [
    "matches = []\n",
    "for i in all_team:\n",
    "    team = i.find_all('td', class_ = 'table-body__cell u-center-text')[0].text\n",
    "    matches.append(team)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3,400', '3,572', '3,866', '2,354', '2,392', '2,753', '2,677', '1,380', '2,902', '1,214', '1,254', '1,098', '808', '673', '919', '693', '821', '476', '128']\n"
     ]
    }
   ],
   "source": [
    "points = []\n",
    "for i in all_team:\n",
    "    team = i.find_all('td', class_ = 'table-body__cell u-center-text')[1].text\n",
    "    points.append(team)\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['113', '112', '110', '107', '100', '92', '89', '73', '71', '53', '46', '42', '35', '32', '31', '28', '26', '19', '4']\n"
     ]
    }
   ],
   "source": [
    "ratting = []\n",
    "for i in all_team:\n",
    "    team = i.find('td', class_ = 'table-body__cell u-text-right rating').text\n",
    "    ratting.append(team)\n",
    "print(ratting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranks</th>\n",
       "      <th>Team Name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>England</td>\n",
       "      <td>30</td>\n",
       "      <td>3,400</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Australia</td>\n",
       "      <td>32</td>\n",
       "      <td>3,572</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>India</td>\n",
       "      <td>35</td>\n",
       "      <td>3,866</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>22</td>\n",
       "      <td>2,354</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,392</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>30</td>\n",
       "      <td>2,753</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>30</td>\n",
       "      <td>2,677</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>19</td>\n",
       "      <td>1,380</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>23</td>\n",
       "      <td>1,214</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>27</td>\n",
       "      <td>1,254</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ranks     Team Name Matches Points Ratting\n",
       "0      2       England      30  3,400     113\n",
       "1      3     Australia      32  3,572     112\n",
       "2      4         India      35  3,866     110\n",
       "3      5      Pakistan      22  2,354     107\n",
       "4      6  South Africa      24  2,392     100\n",
       "5      7    Bangladesh      30  2,753      92\n",
       "6      8     Sri Lanka      30  2,677      89\n",
       "7      9   Afghanistan      19  1,380      73\n",
       "8     10   West Indies      41  2,902      71\n",
       "9     11       Ireland      23  1,214      53\n",
       "10    12      Scotland      27  1,254      46"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Ranks':rank, 'Team Name':team_name, 'Matches':matches, 'Points':points, \"Ratting\": ratting})\n",
    "df.iloc[:11,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odi_bat = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "odi_bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "odi_bat_soup = BeautifulSoup(odi_bat.content)\n",
    "#odi_bat_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bat = odi_bat_soup.find('tbody').find_all(\"tr\", class_ = 'table-body')\n",
    "len(all_bat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '3', '4', '5', '6', '7', '8', '9', '10']\n"
     ]
    }
   ],
   "source": [
    "rank = []\n",
    "\n",
    "for i in all_bat:\n",
    "    player = i.find('td', class_ = \"table-body__cell table-body__cell--position u-text-right\").span.get_text(strip = True)\n",
    "    rank.append(player)\n",
    "print(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Imam-ul-Haq', 'Rassie van der Dussen', 'Quinton de Kock', 'David Warner', 'Steve Smith', 'Jonny Bairstow', 'Virat Kohli', 'Rohit Sharma', 'Kane Williamson']\n"
     ]
    }
   ],
   "source": [
    "Player_name = []\n",
    "for i in all_bat:\n",
    "    name = i.find('td', class_ = \"table-body__cell name\").a.text\n",
    "    Player_name.append(name)\n",
    "print(Player_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PAK', 'SA', 'SA', 'AUS', 'AUS', 'ENG', 'IND', 'IND', 'NZ']\n"
     ]
    }
   ],
   "source": [
    "Nation = []\n",
    "for i in all_bat:\n",
    "    country = i.find('td', class_ = 'table-body__cell nationality-logo').find('span', class_ = \"table-body__logo-text\").text\n",
    "    Nation.append(country)\n",
    "print(Nation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['779', '766', '759', '747', '719', '710', '707', '704', '701']\n"
     ]
    }
   ],
   "source": [
    "ratting = []\n",
    "for i in all_bat:\n",
    "    rate = i.find('td', class_ = \"table-body__cell u-text-right rating\").text\n",
    "    ratting.append(rate)\n",
    "print(ratting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Nation</th>\n",
       "      <th>Ratting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank            Player Name Nation Ratting\n",
       "0    2            Imam-ul-Haq    PAK     779\n",
       "1    3  Rassie van der Dussen     SA     766\n",
       "2    4        Quinton de Kock     SA     759\n",
       "3    5           David Warner    AUS     747\n",
       "4    6            Steve Smith    AUS     719\n",
       "5    7         Jonny Bairstow    ENG     710\n",
       "6    8            Virat Kohli    IND     707\n",
       "7    9           Rohit Sharma    IND     704\n",
       "8   10        Kane Williamson     NZ     701"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rank':rank, 'Player Name':Player_name, 'Nation':Nation, 'Ratting':ratting})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odi_bowlers = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\")\n",
    "odi_bowlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowler_soup = BeautifulSoup(odi_bowlers.content)\n",
    "#bowler_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "all_b = bowler_soup.find('tbody').find_all('tr', class_ = 'table-body')\n",
    "print(len(all_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '3', '4', '5', '6', '7', '8', '9', '10']\n"
     ]
    }
   ],
   "source": [
    "rank = []\n",
    "\n",
    "for i in all_b:\n",
    "    bowl = i.find('div', class_ = 'rankings-table__pos-container').span.get_text(strip = True)\n",
    "    rank.append(bowl)\n",
    "print(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Imam-ul-Haq', 'Rassie van der Dussen', 'Quinton de Kock', 'David Warner', 'Steve Smith', 'Jonny Bairstow', 'Virat Kohli', 'Rohit Sharma', 'Kane Williamson']\n"
     ]
    }
   ],
   "source": [
    "Player_Name = []\n",
    "for i in all_b:\n",
    "    player = i.find('td', class_ = \"table-body__cell name\").a.text\n",
    "    Player_Name.append(player)\n",
    "print(Player_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PAK', 'SA', 'SA', 'AUS', 'AUS', 'ENG', 'IND', 'IND', 'NZ']\n"
     ]
    }
   ],
   "source": [
    "Nation = []\n",
    "for i in all_b:\n",
    "    country = i.find('td', class_ = 'table-body__cell nationality-logo').find('span', class_ = 'table-body__logo-text').text\n",
    "    Nation.append(country)\n",
    "print(Nation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['779', '766', '759', '747', '719', '710', '707', '704', '701']\n"
     ]
    }
   ],
   "source": [
    "ratting = []\n",
    "for i in all_b:\n",
    "    rate = i.find('td', class_ = 'table-body__cell u-text-right rating').text\n",
    "    ratting.append(rate)\n",
    "print(ratting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank            Player Name Country Ratting\n",
       "0    2            Imam-ul-Haq     PAK     779\n",
       "1    3  Rassie van der Dussen      SA     766\n",
       "2    4        Quinton de Kock      SA     759\n",
       "3    5           David Warner     AUS     747\n",
       "4    6            Steve Smith     AUS     719\n",
       "5    7         Jonny Bairstow     ENG     710\n",
       "6    8            Virat Kohli     IND     707\n",
       "7    9           Rohit Sharma     IND     704\n",
       "8   10        Kane Williamson      NZ     701"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rank':rank, 'Player Name':Player_name, 'Country':Nation, 'Ratting':ratting})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women_team = requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "women_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_team = BeautifulSoup(women_team.content)\n",
    "#top_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "all_team = top_team.find('tbody').find_all('tr', class_ = \"table-body\")\n",
    "print(len(all_team))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']\n"
     ]
    }
   ],
   "source": [
    "rank = []\n",
    "for i in all_team:\n",
    "    teams = i.find('td', class_ = \"table-body__cell table-body__cell--position u-text-right\").text\n",
    "    rank.append(teams)\n",
    "print(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['South Africa', 'England', 'India', 'New Zealand', 'West Indies', 'Bangladesh', 'Thailand', 'Pakistan', 'Sri Lanka', 'Ireland', 'Netherlands', 'Zimbabwe']\n"
     ]
    }
   ],
   "source": [
    "team_name = []\n",
    "for i in all_team:\n",
    "    teams = i.find('td', class_ = 'table-body__cell rankings-table__team').find('span', class_ = \"u-hide-phablet\").text\n",
    "    team_name.append(teams)\n",
    "print(team_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['26', '25', '27', '24', '24', '12', '8', '24', '8', '14', '9', '8']\n"
     ]
    }
   ],
   "source": [
    "matches = []\n",
    "for i in all_team:\n",
    "    teams = i.find_all('td', class_ =\"table-body__cell u-center-text\")[0].text\n",
    "    matches.append(teams)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3,098', '2,904', '2,820', '2,425', '2,334', '932', '572', '1,519', '353', '548', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "points = []\n",
    "for i in all_team:\n",
    "    teams = i.find_all('td', class_ = \"table-body__cell u-center-text\")[1].text\n",
    "    points.append(teams)\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['119', '116', '104', '101', '97', '78', '72', '63', '44', '39', '0', '0']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = []\n",
    "for i in all_team:\n",
    "    teams = i.find('td', class_ = \"table-body__cell u-text-right rating\").text\n",
    "    rating.append(teams)\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>England</td>\n",
       "      <td>25</td>\n",
       "      <td>2,904</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>India</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>24</td>\n",
       "      <td>2,425</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>24</td>\n",
       "      <td>2,334</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>12</td>\n",
       "      <td>932</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>8</td>\n",
       "      <td>572</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>24</td>\n",
       "      <td>1,519</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>8</td>\n",
       "      <td>353</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>14</td>\n",
       "      <td>548</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank       Country Matches Points Ratting\n",
       "0     2  South Africa      26  3,098     119\n",
       "1     3       England      25  2,904     116\n",
       "2     4         India      27  2,820     104\n",
       "3     5   New Zealand      24  2,425     101\n",
       "4     6   West Indies      24  2,334      97\n",
       "5     7    Bangladesh      12    932      78\n",
       "6     8      Thailand       8    572      72\n",
       "7     9      Pakistan      24  1,519      63\n",
       "8    10     Sri Lanka       8    353      44\n",
       "9    11       Ireland      14    548      39\n",
       "10   12   Netherlands       9      0       0\n",
       "11   13      Zimbabwe       8      0       0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rank':rank, \"Country\": team_name, \"Matches\":matches, \"Points\":points, \"Ratting\":rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "batsmen = requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")\n",
    "#batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "batswmen_soup = BeautifulSoup(batsmen.content)\n",
    "#batswmen_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_w_bat = batswmen_soup.find('table', class_ = 'table rankings-table').find_all('tr', class_ = 'table-body')\n",
    "len(all_w_bat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11']\n"
     ]
    }
   ],
   "source": [
    "rank_w = []\n",
    "for i in all_w_bat:\n",
    "    team = i.find(\"td\", class_ = \"table-body__cell table-body__cell--position u-text-right\").get_text(strip = True).split(\"(\")[0]\n",
    "    rank_w.append(team)\n",
    "    if len(rank_w) == 10:\n",
    "        break\n",
    "print(rank_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beth Mooney', 'Laura Wolvaardt', 'Natalie Sciver', 'Harmanpreet Kaur', 'Smriti Mandhana', 'Meg Lanning', 'Rachael Haynes', 'Amy Satterthwaite', 'Chamari Athapaththu', 'Ellyse Perry']\n"
     ]
    }
   ],
   "source": [
    "player_name_w = []\n",
    "for i in all_w_bat:\n",
    "    player = i.find('td', class_ = \"table-body__cell rankings-table__name name\").a.text\n",
    "    player_name_w.append(player)\n",
    "    if len(player_name_w)==10:\n",
    "        break\n",
    "print(player_name_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AUS', 'SA', 'ENG', 'IND', 'IND', 'AUS', 'AUS', 'NZ', 'SL', 'AUS']\n"
     ]
    }
   ],
   "source": [
    "Nation_w = []\n",
    "for i in all_w_bat:\n",
    "    country = i.find('td', class_ = \"table-body__cell nationality-logo rankings-table__team\").get_text(strip = True)\n",
    "    Nation_w.append(country)\n",
    "    if len(Nation_w) == 10:\n",
    "        break\n",
    "print(Nation_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['749', '732', '725', '716', '714', '710', '701', '661', '655', '642']\n"
     ]
    }
   ],
   "source": [
    "ratting_w = []\n",
    "for i in all_w_bat:\n",
    "    rate = i.find('td', class_ = \"table-body__cell rating\").text\n",
    "    ratting_w.append(rate)\n",
    "    if len(ratting_w)==10:\n",
    "        break\n",
    "print(ratting_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank          Player Name Country Ratting\n",
       "0    2          Beth Mooney     AUS     749\n",
       "1    3      Laura Wolvaardt      SA     732\n",
       "2    4       Natalie Sciver     ENG     725\n",
       "3    5     Harmanpreet Kaur     IND     716\n",
       "4    6      Smriti Mandhana     IND     714\n",
       "5    7          Meg Lanning     AUS     710\n",
       "6    8       Rachael Haynes     AUS     701\n",
       "7    9    Amy Satterthwaite      NZ     661\n",
       "8   10  Chamari Athapaththu      SL     655\n",
       "9   11         Ellyse Perry     AUS     642"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rank': rank_w, \"Player Name\": player_name_w, \"Country\":Nation_w, \"Ratting\":ratting_w})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_team = BeautifulSoup(top.content)\n",
    "#top_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_w_allround = top_team.find('table', class_ = \"table rankings-table\").find_all('tr', class_ = \"table-body\")\n",
    "len(top_w_allround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20']\n"
     ]
    }
   ],
   "source": [
    "rank_al_w = []\n",
    "for i in top_w_allround:\n",
    "    rank = i.find('td', class_ = \"table-body__cell table-body__cell--position u-text-right\").get_text(strip = True).split(\"(\")[0]\n",
    "    rank_al_w.append(rank)\n",
    "print(rank_al_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ellyse Perry', 'Natalie Sciver', 'Amelia Kerr', 'Marizanne Kapp', 'Deepti Sharma', 'Ashleigh Gardner', 'Jess Jonassen', 'Jhulan Goswami', 'Katherine Brunt', 'Nida Dar', 'Sophie Ecclestone', 'Rumana Ahmed', 'Chloe-Lesleigh Tryon', 'Stafanie Taylor', 'Sophie Devine', 'Salma Khatun', 'Chamari Athapaththu', 'Charlotte Dean', 'Sune Luus']\n"
     ]
    }
   ],
   "source": [
    "player_al_w = []\n",
    "for i in top_w_allround:\n",
    "    player = i.find('td', class_ = \"table-body__cell rankings-table__name name\").a.text\n",
    "    player_al_w.append(player)\n",
    "print(player_al_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AUS', 'ENG', 'NZ', 'SA', 'IND', 'AUS', 'AUS', 'IND', 'ENG', 'PAK', 'ENG', 'BAN', 'SA', 'WI', 'NZ', 'BAN', 'SL', 'ENG', 'SA']\n"
     ]
    }
   ],
   "source": [
    "nation_al_w = []\n",
    "for i in top_w_allround:\n",
    "    country = i.find(\"td\", class_ = \"table-body__cell nationality-logo rankings-table__team\").get_text(strip = True)\n",
    "    nation_al_w.append(country)\n",
    "print(nation_al_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['374', '357', '356', '349', '322', '270', '246', '214', '207', '205', '201', '201', '197', '192', '189', '178', '178', '175', '171']\n"
     ]
    }
   ],
   "source": [
    "ratting_al_w = []\n",
    "for i in top_w_allround:\n",
    "    rate = i.find_all(\"td\", class_ = \"table-body__cell rating\")[0].text\n",
    "    ratting_al_w.append(rate)\n",
    "print(ratting_al_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['548 v West Indies, 11/09/2019', '395 v South Africa, 11/07/2022', '356 v West Indies, 25/09/2022', '419 v West Indies, 10/09/2021', '397 v South Africa, 09/10/2019', '279 v West Indies, 30/03/2022', '308 v West Indies, 11/09/2019', '308 v Australia, 02/02/2016', '296 v Australia, 03/02/2022', '209 v Ireland, 06/11/2022', '217 v South Africa, 31/03/2022', '198 v South Africa, 05/03/2022', '197 v England, 18/07/2022', '559 v New Zealand, 10/10/2013', '305 v Australia, 05/10/2020', '170 v Australia, 25/03/2022', '187 v South Africa, 17/02/2019', '175 v India, 24/09/2022', '223 v Ireland, 17/06/2022']\n"
     ]
    }
   ],
   "source": [
    "career_best = []\n",
    "for i in top_w_allround:\n",
    "    career = i.find('td', class_ = \"table-body__cell u-text-right u-hide-phablet\").get_text(strip = True)\n",
    "    career_best.append(career)\n",
    "print(career_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratting</th>\n",
       "      <th>Career Best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "      <td>548 v West Indies, 11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>357</td>\n",
       "      <td>395 v South Africa, 11/07/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>356</td>\n",
       "      <td>356 v West Indies, 25/09/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "      <td>419 v West Indies, 10/09/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>322</td>\n",
       "      <td>397 v South Africa, 09/10/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>270</td>\n",
       "      <td>279 v West Indies, 30/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>246</td>\n",
       "      <td>308 v West Indies, 11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>214</td>\n",
       "      <td>308 v Australia, 02/02/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>207</td>\n",
       "      <td>296 v Australia, 03/02/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>PAK</td>\n",
       "      <td>205</td>\n",
       "      <td>209 v Ireland, 06/11/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>201</td>\n",
       "      <td>217 v South Africa, 31/03/2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank        Player Name Country Ratting                     Career Best\n",
       "0     2       Ellyse Perry     AUS     374   548 v West Indies, 11/09/2019\n",
       "1     3     Natalie Sciver     ENG     357  395 v South Africa, 11/07/2022\n",
       "2     4        Amelia Kerr      NZ     356   356 v West Indies, 25/09/2022\n",
       "3     5     Marizanne Kapp      SA     349   419 v West Indies, 10/09/2021\n",
       "4     6      Deepti Sharma     IND     322  397 v South Africa, 09/10/2019\n",
       "5     7   Ashleigh Gardner     AUS     270   279 v West Indies, 30/03/2022\n",
       "6     8      Jess Jonassen     AUS     246   308 v West Indies, 11/09/2019\n",
       "7     9     Jhulan Goswami     IND     214     308 v Australia, 02/02/2016\n",
       "8    10    Katherine Brunt     ENG     207     296 v Australia, 03/02/2022\n",
       "9    11           Nida Dar     PAK     205       209 v Ireland, 06/11/2022\n",
       "10   12  Sophie Ecclestone     ENG     201  217 v South Africa, 31/03/2022"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Rank\": rank_al_w, \"Player Name\": player_al_w, \"Country\": nation_al_w, \"Ratting\":ratting_al_w, \"Career Best\":career_best})\n",
    "df.iloc[0:11,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnbc = requests.get(\"https://www.cnbc.com/world/\")\n",
    "cnbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnbc_soup = BeautifulSoup(cnbc.content)\n",
    "#cnbc_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Parking lots are becoming as important as cars in climate change efforts', \"Amazon's cloud unit faces cost-sensitive customers as economic fears mount\", 'Don’t overlook this health warning on your decorative holiday lights', 'How electric air taxis could shake up the airline industry in the next decade', \"I raised 2 successful CEOs and a doctor. Here's the No. 1 skill I wish more parents taught kids today\", 'Delta pilots would get more than 30% in pay raises under new contract deal', 'Men participate less in 401(k) plans than women unless they are auto-enrolled', 'The best U.S. states to raise a family if you make over $70,000 a year', 'Susan Cain: This Bob Dylan-inspired phrase can make tough conversations easier', '', '', 'Celsius users with crypto collateral stuck turn to bankruptcy process for relief', \"Cramer's lightning round: Let Extreme Networks cool off a little before buying\", 'Jim Cramer says these 3 apparel stocks benefit from return to office', 'Cramer’s week ahead: Markets need a strong job market, tame inflation to stay up', '', '', 'Biden administration will end monkeypox public health emergency', '', 'GM, LG investing $275 million to expand Tennessee EV battery plant', '', \"The Fed's path to a 'Goldilocks' economy just got a little more complicated\", '', 'Biden condemns antisemitism as Ye praises Hitler days after dinner with Trump', 'Georgia man arrested for shooting boy campaigning for Warnock in Walker runoff', '', 'The biggest tax changes to know before filing your 2022 return', \"'This is a crisis.' Why more workers need access to retirement savings\", 'Carnival’s Princess Cruises will return to Japan after nearly three years', 'Tech layoffs may not be a bad omen for U.S. economy at large']\n"
     ]
    }
   ],
   "source": [
    "Headline = cnbc_soup.find('ul', class_ = \"LatestNews-list\").find_all(\"li\", class_ = \"LatestNews-item\")\n",
    "news = []\n",
    "for i in Headline:\n",
    "    latest_news = i.find(\"div\", class_ = \"LatestNews-headlineWrapper\").a.text\n",
    "    news.append(latest_news)\n",
    "print(news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5 Hours Ago', '6 Hours Ago', '6 Hours Ago', '6 Hours Ago', '6 Hours Ago', '6 Hours Ago', '7 Hours Ago', '7 Hours Ago', '7 Hours Ago', '8 Hours Ago', '8 Hours Ago', '8 Hours Ago', '21 Hours Ago', '21 Hours Ago', '22 Hours Ago', '23 Hours Ago', '23 Hours Ago', '24 Hours Ago', 'December 2, 2022', 'December 2, 2022', 'December 2, 2022', 'December 2, 2022', 'December 2, 2022', 'December 2, 2022', 'December 2, 2022', 'December 2, 2022', 'December 2, 2022', 'December 2, 2022', 'December 2, 2022', 'December 2, 2022']\n"
     ]
    }
   ],
   "source": [
    "time = []\n",
    "for i in Headline:\n",
    "    time_of_news = i.find(\"div\", class_ = \"LatestNews-headlineWrapper\").find(\"time\", class_ = \"LatestNews-timestamp\").text\n",
    "    time.append(time_of_news)\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Related URLs https://www.cnbc.com/2022/12/03/parking-lots-becoming-as-important-as-cars-in-climate-change-efforts.html\n",
      "Related URLs https://www.cnbc.com/2022/12/03/aws-faces-cost-sensitive-customers-at-reinvent-as-economic-fears-mount.html\n",
      "Related URLs https://www.cnbc.com/2022/12/03/dont-overlook-this-health-and-safety-warning-on-your-holiday-lights.html\n",
      "Related URLs https://www.cnbc.com/2022/12/03/how-electric-air-taxis-could-shake-up-the-airline-industry.html\n",
      "Related URLs https://www.cnbc.com/2022/12/03/i-raised-2-successful-ceos-and-a-doctor-heres-the-no-1-skill-parents-are-failing-to-teach-kids-today.html\n",
      "Related URLs https://www.cnbc.com/2022/12/03/delta-pilots-would-get-more-than-30percent-in-pay-raises-under-new-contract-deal.html\n",
      "Related URLs https://www.cnbc.com/2022/12/03/men-participate-less-in-401k-plans-than-women-unless-auto-enrolled.html\n",
      "Related URLs https://www.cnbc.com/2022/12/03/best-states-raise-a-family-rocket-mortgage.html\n",
      "Related URLs https://www.cnbc.com/2022/12/03/bestselling-author-susan-cain-how-to-make-tough-conversations-easier.html\n",
      "Related URLs https://www.cnbc.com/2022/12/03/the-difference-between-this-comeback-and-the-markets-last-failed-bear-market-bounce.html\n",
      "Related URLs https://www.cnbc.com/2022/12/03/goldman-says-buy-these-five-stocks-in-a-weakening-macro-environment.html\n",
      "Related URLs https://www.cnbc.com/2022/12/03/celsius-users-with-crypto-collateral-stuck-turn-to-bankruptcy-process.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/cramers-lightning-round-let-extreme-networks-cool-off-before-buying.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/jim-cramer-says-these-3-apparel-stocks-benefit-from-return-to-office.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/cramers-week-ahead-markets-need-a-strong-job-market-tame-inflation.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/pro-picks-watch-all-of-fridays-big-stock-calls-on-cnbc.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/reits-offer-enormous-opportunity-says-gilman-hills-jenny-harrington.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/biden-administration-will-end-monkeypox-public-health-emergency.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/expect-more-choppiness-ahead-after-a-week-of-mixed-market-signals.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/gm-lg-investing-275-million-to-expand-tennessee-ev-battery-plant.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/big-tech-stocks-are-at-historical-lows-these-names-have-potential-halftime-report-traders-say.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/the-feds-path-to-a-goldilocks-economy-just-got-more-complicated.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/three-things-crypto-investors-need-to-know-in-a-post-ftx-world-according-to-financial-advisors.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/biden-condemns-antisemitism-after-ye-praises-hitler-post-trump-dinner.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/georgia-election-runoff-man-shot-warnock-election-worker.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/markets-looking-for-the-next-catalyst-might-latch-on-to-worries-about-2023.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/the-biggest-tax-changes-to-know-before-filing-your-2022-return.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/why-more-workers-need-access-to-retirement-savings.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/carnivals-princess-cruises-will-return-to-japan-after-over-two-years.html\n",
      "Related URLs https://www.cnbc.com/2022/12/02/tech-layoffs-may-not-be-a-bad-omen-for-us-economy-at-large.html\n"
     ]
    }
   ],
   "source": [
    "new_link = []\n",
    "# for i in Headline:\n",
    "#     link = i.find(\"a\", href = True)\n",
    "# print(\"Found the URl\", i['href'])\n",
    "\n",
    "for i in cnbc_soup.find_all('a', class_ = \"LatestNews-headline\", href = True):\n",
    "    new_link.append(i)\n",
    "    print(\"Related URLs\", i['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ai_articles = requests.get(\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\")\n",
    "Ai_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_soup = BeautifulSoup(Ai_articles.content)\n",
    "#article_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Articles = article_soup.find(\"ul\", class_ = \"sc-9zxyh7-0 cMKaMj\").find_all(\"li\", class_ = \"sc-9zxyh7-1 sc-9zxyh7-2 kOEIEO hvoVxs\")\n",
    "len(Articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Paper Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reward is enough', 'Making sense of raw input', 'Law and logic: A review from an argumentation perspective', 'Creativity and artificial intelligence', 'Artificial cognition for social human–robot interaction: An implementation', 'Explanation in artificial intelligence: Insights from the social sciences', 'Making sense of sensory input', 'Conflict-based search for optimal multi-agent pathfinding', 'Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning', 'The Hanabi challenge: A new frontier for AI research', 'Evaluating XAI: A comparison of rule-based and example-based explanations', 'Argumentation in artificial intelligence', 'Algorithms for computing strategies in two-player simultaneous move games', 'Multiple object tracking: A literature review', 'Selection of relevant features and examples in machine learning', 'A survey of inverse reinforcement learning: Challenges, methods and progress', 'Explaining individual predictions when features are dependent: More accurate approximations to Shapley values', 'A review of possible effects of cognitive biases on interpretation of rule-based machine learning models', 'Integrating social power into the decision-making of cognitive agents', \"“That's (not) the output I expected!” On the role of end user expectations in creating explanations of AI systems\", 'Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies', 'Algorithm runtime prediction: Methods & evaluation', 'Wrappers for feature subset selection', 'Commonsense visual sensemaking for autonomous driving – On generalised neurosymbolic online abduction integrating vision and semantics', 'Quantum computation, quantum theory and AI']\n"
     ]
    }
   ],
   "source": [
    "paper_title = []\n",
    "for i in Articles:\n",
    "    title = i.find(\"h2\", class_ = \"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\").text\n",
    "    paper_title.append(title)\n",
    "print(paper_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Silver, David, Singh, Satinder, Precup, Doina, Sutton, Richard S. ', 'Evans, Richard, Bošnjak, Matko and 5 more', 'Prakken, Henry, Sartor, Giovanni ', 'Boden, Margaret A. ', 'Lemaignan, Séverin, Warnier, Mathieu and 3 more', 'Miller, Tim ', 'Evans, Richard, Hernández-Orallo, José and 3 more', 'Sharon, Guni, Stern, Roni, Felner, Ariel, Sturtevant, Nathan R. ', 'Sutton, Richard S., Precup, Doina, Singh, Satinder ', 'Bard, Nolan, Foerster, Jakob N. and 13 more', 'van der Waa, Jasper, Nieuwburg, Elisabeth, Cremers, Anita, Neerincx, Mark ', 'Bench-Capon, T.J.M., Dunne, Paul E. ', 'Bošanský, Branislav, Lisý, Viliam and 3 more', 'Luo, Wenhan, Xing, Junliang and 4 more', 'Blum, Avrim L., Langley, Pat ', 'Arora, Saurabh, Doshi, Prashant ', 'Aas, Kjersti, Jullum, Martin, Løland, Anders ', 'Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Johannes ', 'Pereira, Gonçalo, Prada, Rui, Santos, Pedro A. ', 'Riveiro, Maria, Thill, Serge ', 'Kenny, Eoin M., Ford, Courtney, Quinn, Molly, Keane, Mark T. ', 'Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyton-Brown, Kevin ', 'Kohavi, Ron, John, George H. ', 'Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srikrishna ', 'Ying, Mingsheng ']\n"
     ]
    }
   ],
   "source": [
    "Author = []\n",
    "for i in Articles:\n",
    "    auth = i.find(\"span\", class_ = \"sc-1w3fpd7-0 dnCnAO\").text\n",
    "    Author.append(auth)\n",
    "print(Author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) Published Date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['October 2021', 'October 2021', 'October 2015', 'August 1998', 'June 2017', 'February 2019', 'April 2021', 'February 2015', 'August 1999', 'March 2020', 'February 2021', 'October 2007', 'August 2016', 'April 2021', 'December 1997', 'August 2021', 'September 2021', 'June 2021', 'December 2016', 'September 2021', 'May 2021', 'January 2014', 'December 1997', 'October 2021', 'February 2010']\n"
     ]
    }
   ],
   "source": [
    "publish_d = []\n",
    "for i in Articles:\n",
    "    publish = i.find(\"span\", class_ = \"sc-1thf9ly-2 dvggWt\").text\n",
    "    publish_d.append(publish)\n",
    "print(publish_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370221000862\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370221000722\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370215000910\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370298000551\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370216300790\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370218305988\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370220301855\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370214001386\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370299000521\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370219300116\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370220301533\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370207000793\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370216300285\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370220301958\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370297000635\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370221000515\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370221000539\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370221000096\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370216300868\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370221000588\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370221000102\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370213001082\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S000437029700043X\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370221000734\n",
      "Related Urls https://www.sciencedirect.com/science/article/pii/S0004370209001398\n"
     ]
    }
   ],
   "source": [
    "url = []\n",
    "for i in article_soup.find_all(\"a\", class_ =\"sc-5smygv-0 fIXTHm\", href = True):\n",
    "    url.append(i)\n",
    "    print(\"Related Urls\", i['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) Write a python program to scrape mentioned details from dineout.co.in :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant = requests.get(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")\n",
    "restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_soup = BeautifulSoup(restaurant.content)\n",
    "#rest_soup\n",
    "\n",
    "all_rest = rest_soup.find(\"div\", class_ =\"restnt-card-wrap-new\")\n",
    "len(all_rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Restaurant name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Castle Barbeque', 'Jungle Jamboree', 'Castle Barbeque', 'Cafe Knosh', 'The Barbeque Company', 'India Grill', 'Delhi Barbeque', 'The Monarch - Bar Be Que Village', 'Indian Grill Room']\n"
     ]
    }
   ],
   "source": [
    "Restaurant_name = []\n",
    "for i in all_rest:\n",
    "    rest_name = i.find(\"div\", class_ = \"restnt-info cursor\").a.text\n",
    "    Restaurant_name.append(rest_name)\n",
    "print(Restaurant_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chinese', 'North Indian', 'Chinese', 'Italian', 'North Indian', 'North Indian', 'North Indian', 'North Indian', 'North Indian']\n"
     ]
    }
   ],
   "source": [
    "Cuisine = []\n",
    "for i in all_rest:\n",
    "    cuisine_type = i.find(\"span\", class_ = \"double-line-ellipsis\").a.text\n",
    "    Cuisine.append(cuisine_type)\n",
    "print(Cuisine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Connaught Place', '3CS Mall,', 'Pacific Mall,', 'The Leela Ambience Convention Hotel,', 'Gardens Galleria,', 'Hilton Garden Inn,', 'Taurus Sarovar Portico,', 'Indirapuram Habitat Centre,', 'Suncity Business Tower,']\n"
     ]
    }
   ],
   "source": [
    "Location = []\n",
    "for i in all_rest:\n",
    "    loca = i.find(\"div\", class_ = \"restnt-loc ellipsis\").a.text\n",
    "    Location.append(loca)\n",
    "print(Location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv) Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4.1', '3.9', '3.9', '4.3', '4', '3.9', '3.6', '3.8', '4.3']\n"
     ]
    }
   ],
   "source": [
    "Ratting = []\n",
    "for i in all_rest:\n",
    "    rate = i.find(\"div\", class_ = \"restnt-rating rating-4\").text\n",
    "    Ratting.append(rate)\n",
    "print(Ratting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/k/b/p86792-16062953735fbe1f4d3fb7e.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/p/m/p59633-166088382462ff137009010.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/j/o/p38113-15959192065f1fcb666130c.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/p/m/p406-15438184745c04ccea491bc.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/7/p/k/p79307-16051787755fad1597f2bf9.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/v/t/p2687-1482477169585cce712b90f.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/d/i/p52501-1661855212630de5eceb6d2.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/n/o/p34822-15599107305cfa594a13c24.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/y/f/p549-165000147262590640c0afc.jpg?tr=tr:n-medium']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = []\n",
    "for i in rest_soup.find_all(\"img\", class_ = \"no-img\"):\n",
    "    image.append(i.get('data-src'))\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10) Write a python program to scrape the details of top publications from Google Scholar from \n",
    "https://scholar.google.com/citations?view_op=top_venues&hl=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publications = requests.get(\"https://scholar.google.com/citations?view_op=top_venues&hl=en\")\n",
    "publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_soup = BeautifulSoup(publications.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '10.', '11.', '12.', '13.', '14.', '15.', '16.', '17.', '18.', '19.', '20.', '21.', '22.', '23.', '24.', '25.', '26.', '27.', '28.', '29.', '30.', '31.', '32.', '33.', '34.', '35.', '36.', '37.', '38.', '39.', '40.', '41.', '42.', '43.', '44.', '45.', '46.', '47.', '48.', '49.', '50.', '51.', '52.', '53.', '54.', '55.', '56.', '57.', '58.', '59.', '60.', '61.', '62.', '63.', '64.', '65.', '66.', '67.', '68.', '69.', '70.', '71.', '72.', '73.', '74.', '75.', '76.', '77.', '78.', '79.', '80.', '81.', '82.', '83.', '84.', '85.', '86.', '87.', '88.', '89.', '90.', '91.', '92.', '93.', '94.', '95.', '96.', '97.', '98.', '99.', '100.']\n"
     ]
    }
   ],
   "source": [
    "pub_rank = []\n",
    "for i in pub_soup.find_all(\"td\", class_ = \"gsc_mvt_p\"):\n",
    "    pub_rank.append(i.get_text(strip =True))\n",
    "print(pub_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nature', 'The New England Journal of Medicine', 'Science', 'IEEE/CVF Conference on Computer Vision and Pattern Recognition', 'The Lancet', 'Advanced Materials', 'Nature Communications', 'Cell', 'International Conference on Learning Representations', 'Neural Information Processing Systems', 'JAMA', 'Chemical Reviews', 'Proceedings of the National Academy of Sciences', 'Angewandte Chemie', 'Chemical Society Reviews', 'Journal of the American Chemical Society', 'IEEE/CVF International Conference on Computer Vision', 'Nucleic Acids Research', 'International Conference on Machine Learning', 'Nature Medicine', 'Renewable and Sustainable Energy Reviews', 'Science of The Total Environment', 'Advanced Energy Materials', 'Journal of Clinical Oncology', 'ACS Nano', 'Journal of Cleaner Production', 'Advanced Functional Materials', 'Physical Review Letters', 'Scientific Reports', 'The Lancet Oncology', 'Energy & Environmental Science', 'IEEE Access', 'PLoS ONE', 'Science Advances', 'Journal of the American College of Cardiology', 'Applied Catalysis B: Environmental', 'Nature Genetics', 'BMJ', 'Circulation', 'European Conference on Computer Vision', 'International Journal of Molecular Sciences', 'Nature Materials', 'Chemical engineering journal', 'AAAI Conference on Artificial Intelligence', 'Journal of Materials Chemistry A', 'ACS Applied Materials & Interfaces', 'Nature Biotechnology', 'The Lancet Infectious Diseases', 'Frontiers in Immunology', 'Applied Energy', 'Nano Energy', 'Nature Energy', 'Meeting of the Association for Computational Linguistics (ACL)', 'The Astrophysical Journal', 'Gastroenterology', 'Nature Methods', 'IEEE Transactions on Pattern Analysis and Machine Intelligence', 'Cochrane Database of Systematic Reviews', 'Blood', 'Neuron', 'Nano Letters', 'Morbidity and Mortality Weekly Report', 'European Heart Journal', 'Nature Nanotechnology', 'ACS Catalysis', 'Nature Neuroscience', 'American Economic Review', 'Journal of High Energy Physics', 'IEEE Communications Surveys & Tutorials', 'Annals of Oncology', 'Nutrients', 'Accounts of Chemical Research', 'Immunity', 'Environmental Science & Technology', 'Nature Reviews. Molecular Cell Biology', 'Gut', 'Physical Review D', 'ACS Energy Letters', 'Monthly Notices of the Royal Astronomical Society', 'Conference on Empirical Methods in Natural Language Processing (EMNLP)', 'Clinical Infectious Diseases', 'Cell Metabolism', 'Nature Reviews Immunology', 'Joule', 'Nature Photonics', 'International Journal of Environmental Research and Public Health', 'Environmental Pollution', 'Computers in Human Behavior', 'Frontiers in Microbiology', 'Nature Physics', 'Small', 'Cell Reports', 'Molecular Cell', 'Clinical Cancer Research', 'Bioresource Technology', 'Journal of Business Research', 'Molecular Cancer', 'Sensors', 'Nature Climate Change', 'IEEE Internet of Things Journal']\n"
     ]
    }
   ],
   "source": [
    "public = []\n",
    "for i in pub_soup.find_all(\"td\", class_ = \"gsc_mvt_t\"):\n",
    "    public.append(i.get_text(strip =True))\n",
    "print(public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) h5-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['444', '432', '401', '389', '354', '312', '307', '300', '286', '278', '267', '265', '256', '245', '244', '242', '239', '238', '237', '235', '227', '225', '220', '213', '211', '211', '210', '207', '206', '202', '202', '200', '198', '197', '195', '192', '191', '190', '189', '186', '183', '181', '181', '180', '178', '177', '175', '173', '173', '173', '172', '170', '169', '167', '166', '165', '165', '165', '165', '164', '164', '163', '163', '163', '163', '162', '160', '160', '159', '159', '159', '159', '158', '158', '155', '155', '155', '155', '155', '154', '153', '153', '152', '152', '152', '152', '152', '152', '151', '151', '150', '149', '149', '146', '146', '145', '145', '145', '144', '144']\n"
     ]
    }
   ],
   "source": [
    "h5_index = []\n",
    "for i in pub_soup.find_all(\"a\", class_ = \"gs_ibl gsc_mp_anchor\"):\n",
    "    #p = i.find(\"a\",class_ = \"gs_ibl gsc_mp_anchor\").get_text(strip =True)\n",
    "    h5_index.append(i.text)\n",
    "print(h5_index)\n",
    "# h5_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['444',\n",
       " '667',\n",
       " '432',\n",
       " '780',\n",
       " '401',\n",
       " '614',\n",
       " '389',\n",
       " '627',\n",
       " '354',\n",
       " '635',\n",
       " '312',\n",
       " '418',\n",
       " '307',\n",
       " '428',\n",
       " '300',\n",
       " '505',\n",
       " '286',\n",
       " '533',\n",
       " '278',\n",
       " '436',\n",
       " '267',\n",
       " '425',\n",
       " '265',\n",
       " '444',\n",
       " '256',\n",
       " '364',\n",
       " '245',\n",
       " '332',\n",
       " '244',\n",
       " '386',\n",
       " '242',\n",
       " '344',\n",
       " '239',\n",
       " '415',\n",
       " '238',\n",
       " '550',\n",
       " '237',\n",
       " '421',\n",
       " '235',\n",
       " '389',\n",
       " '227',\n",
       " '324',\n",
       " '225',\n",
       " '311',\n",
       " '220',\n",
       " '300',\n",
       " '213',\n",
       " '315',\n",
       " '211',\n",
       " '277',\n",
       " '211',\n",
       " '273',\n",
       " '210',\n",
       " '280',\n",
       " '207',\n",
       " '294',\n",
       " '206',\n",
       " '274',\n",
       " '202',\n",
       " '329',\n",
       " '202',\n",
       " '290',\n",
       " '200',\n",
       " '303',\n",
       " '198',\n",
       " '278',\n",
       " '197',\n",
       " '294',\n",
       " '195',\n",
       " '276',\n",
       " '192',\n",
       " '246',\n",
       " '191',\n",
       " '297',\n",
       " '190',\n",
       " '307',\n",
       " '189',\n",
       " '301',\n",
       " '186',\n",
       " '321',\n",
       " '183',\n",
       " '253',\n",
       " '181',\n",
       " '265',\n",
       " '181',\n",
       " '224',\n",
       " '180',\n",
       " '296',\n",
       " '178',\n",
       " '220',\n",
       " '177',\n",
       " '223',\n",
       " '175',\n",
       " '315',\n",
       " '173',\n",
       " '296',\n",
       " '173',\n",
       " '228',\n",
       " '173',\n",
       " '217',\n",
       " '172',\n",
       " '232',\n",
       " '170',\n",
       " '314',\n",
       " '169',\n",
       " '304',\n",
       " '167',\n",
       " '234',\n",
       " '166',\n",
       " '254',\n",
       " '165',\n",
       " '296',\n",
       " '165',\n",
       " '293',\n",
       " '165',\n",
       " '243',\n",
       " '165',\n",
       " '229',\n",
       " '164',\n",
       " '231',\n",
       " '164',\n",
       " '207',\n",
       " '163',\n",
       " '302',\n",
       " '163',\n",
       " '265',\n",
       " '163',\n",
       " '264',\n",
       " '163',\n",
       " '220',\n",
       " '162',\n",
       " '248',\n",
       " '160',\n",
       " '263',\n",
       " '160',\n",
       " '220',\n",
       " '159',\n",
       " '304',\n",
       " '159',\n",
       " '243',\n",
       " '159',\n",
       " '214',\n",
       " '159',\n",
       " '211',\n",
       " '158',\n",
       " '242',\n",
       " '158',\n",
       " '214',\n",
       " '155',\n",
       " '340',\n",
       " '155',\n",
       " '235',\n",
       " '155',\n",
       " '217',\n",
       " '155',\n",
       " '212',\n",
       " '155',\n",
       " '194',\n",
       " '154',\n",
       " '249',\n",
       " '153',\n",
       " '278',\n",
       " '153',\n",
       " '211',\n",
       " '152',\n",
       " '292',\n",
       " '152',\n",
       " '233',\n",
       " '152',\n",
       " '228',\n",
       " '152',\n",
       " '225',\n",
       " '152',\n",
       " '222',\n",
       " '152',\n",
       " '214',\n",
       " '151',\n",
       " '225',\n",
       " '151',\n",
       " '222',\n",
       " '150',\n",
       " '196',\n",
       " '149',\n",
       " '205',\n",
       " '149',\n",
       " '202',\n",
       " '146',\n",
       " '201',\n",
       " '146',\n",
       " '190',\n",
       " '145',\n",
       " '233',\n",
       " '145',\n",
       " '209',\n",
       " '145',\n",
       " '201',\n",
       " '144',\n",
       " '228',\n",
       " '144',\n",
       " '212']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_median = []\n",
    "for i in pub_soup.find_all(\"td\", class_ = \"gsc_mvt_n\"):\n",
    "    h5_median.append(i.text)\n",
    "h5_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks - Amir Ali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
